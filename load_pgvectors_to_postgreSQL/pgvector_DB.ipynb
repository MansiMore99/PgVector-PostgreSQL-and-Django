{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Database with Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pgvector is an extension for PostgreSQL that enables the storage and manipulation of vector data directly within the database. This allows you to perform advanced vector operations, such as similarity searches, nearest neighbor searches, and clustering, all within the familiar SQL environment of PostgreSQL. It's particularly useful for applications involving machine learning, natural language processing, and other tasks where vector data is prevalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.32.0)\n",
      "Requirement already satisfied: psycopg2 in /opt/anaconda3/lib/python3.11/site-packages (2.9.9)\n",
      "Requirement already satisfied: wget in /opt/anaconda3/lib/python3.11/site-packages (3.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Required Modules\n",
    "! pip install openai psycopg2 wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/run/postgresql:5432 - accepting connections\n",
      "\u001b[1m\n",
      "What's next?\n",
      "\u001b[0m  Try Docker Debug for seamless, persistent debugging tools in any container or image → \u001b[36mdocker debug postgres-pgvector\u001b[0m\n",
      "  Learn more at https://docs.docker.com/go/debug-cli/\n"
     ]
    }
   ],
   "source": [
    "# Wait for Postgres to be ready\n",
    "! while ! docker exec -it postgres-pgvector pg_isready -U postgres; do sleep 1; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command below to start PostgreSQL with pgvector in Docker:\n",
    "#! docker run --name pgvector -e POSTGRES_PASSWORD=postgres -p 5432:5432 -d pgvector/pgvector:0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  extension \"vector\" already exists\n",
      "\u001b[1m\n",
      "What's next?\n",
      "\u001b[0m  Try Docker Debug for seamless, persistent debugging tools in any container or image → \u001b[36mdocker debug postgres-pgvector\u001b[0m\n",
      "  Learn more at https://docs.docker.com/go/debug-cli/\n"
     ]
    }
   ],
   "source": [
    "# Enable the pgvector extension by connecting to the database instance from within the container with psql and running the CREATE EXTENSION vector command:\n",
    "! docker exec -it postgres-pgvector psql -U postgres -d postgres -c \"CREATE EXTENSION vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "openai_key = os.getenv('YOUR_API_KEY')\n",
    "\n",
    "if (openai_key == None):\n",
    "    openai_key = getpass('Provide your OpenAI API key: ')\n",
    "\n",
    "if (not openai_key):\n",
    "    raise Exception('No OpenAI API key provided. Please set the OPENAI_API_KEY environment variable or provide it when prompted.')\n",
    "\n",
    "openai.api_key = openai_key\n",
    "\n",
    "print('OpenAI API key set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Movies Dataset With Embeddings\n",
    "\n",
    "This is a movies dataset with over 45,000 movies and 26 million ratings from over 270,000 users. The original data was taken from Kaggle and updated in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the schema file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'cdn-lfs-us-1.huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished downloading the files.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "schema_file = \"https://huggingface.co/datasets/denismagda/movies/raw/main/movie_schema.sql\"\n",
    "data_file = \"https://huggingface.co/datasets/denismagda/movies/resolve/main/movie_data_with_openai_embeddings.sql\"\n",
    "\n",
    "print('Downloading the schema file...')\n",
    "schema_response = requests.get(schema_file, verify=False)\n",
    "with open('movie_schema.sql', 'wb') as file:\n",
    "    file.write(schema_response.content)\n",
    "\n",
    "print('Downloading the data file...')\n",
    "data_response = requests.get(data_file, verify=False)\n",
    "with open('movie_data_with_openai_embeddings.sql', 'wb') as file:\n",
    "    file.write(data_response.content)\n",
    "\n",
    "print('Finished downloading the files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --force-reinstall psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "Successfully connected to PostgreSQL.\n",
      "Creating the schema...\n",
      "Loading the data. It might take a minute...\n",
      "13 movies loaded.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "print('Connecting to PostgreSQL...')\n",
    "conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=password\")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print('Successfully connected to PostgreSQL.')\n",
    "\n",
    "def execute_sql_script(cursor, file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        sql_commands = file.read().split(';')  # Split commands by semicolon\n",
    "        for command in sql_commands:\n",
    "            command = command.strip()\n",
    "            if command:  # Skip empty commands\n",
    "                cursor.execute(sql.SQL(command))\n",
    "\n",
    "# Create the schema\n",
    "print('Creating the schema...')\n",
    "execute_sql_script(cursor, 'movies_schema.sql')\n",
    "conn.commit()\n",
    "\n",
    "# Load the data\n",
    "print('Loading the data. It might take a minute...')\n",
    "execute_sql_script(cursor, 'movie_data_with_openai_embedded.sql')\n",
    "conn.commit()\n",
    "\n",
    "# Verify the data load\n",
    "cursor.execute('SELECT COUNT(*) FROM movie')\n",
    "result = cursor.fetchone()\n",
    "\n",
    "print(f'{result[0]} movies loaded.')\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
